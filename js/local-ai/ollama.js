/**
 * Novel Translator Pro - Ollama Local API Integration
 * T√≠ch h·ª£p Ollama ƒë·ªÉ d·ªãch truy·ªán v·ªõi AI local
 */

// ============================================
// OLLAMA SETTINGS
// ============================================
let useOllama = false;
let ollamaUrl = 'http://localhost:11434';
let ollamaModel = 'huihui_ai/qwen3-abliterated:4b';

// Track Ollama speed
let ollamaChunkTimes = [];
let ollamaTotalChunks = 0;

// ============================================
// TOGGLE & CONNECTION
// ============================================

// Toggle Ollama mode
function toggleOllamaMode() {
    const toggle = document.getElementById('useOllamaToggle');
    const settings = document.getElementById('ollamaSettings');
    const badge = document.getElementById('ollamaStatus');

    useOllama = toggle.checked;

    if (useOllama) {
        settings.style.display = 'block';
        badge.textContent = 'B·∫≠t';
        badge.classList.add('active');
        showToast('ü¶ô ƒê√£ chuy·ªÉn sang Ollama Local API!', 'success');
    } else {
        settings.style.display = 'none';
        badge.textContent = 'T·∫Øt';
        badge.classList.remove('active');
        showToast('‚òÅÔ∏è ƒê√£ chuy·ªÉn sang Gemini Cloud API!', 'info');
    }

    saveOllamaSettings();
}

// Test Ollama connection
async function testOllamaConnection() {
    const resultDiv = document.getElementById('ollamaTestResult');
    const url = document.getElementById('ollamaUrl').value.trim();
    const model = document.getElementById('ollamaModel').value.trim();

    resultDiv.className = 'ollama-test-result info';
    resultDiv.textContent = 'üîç ƒêang ki·ªÉm tra k·∫øt n·ªëi...';

    try {
        const response = await fetch(`${url}/api/tags`, {
            method: 'GET',
            headers: { 'Content-Type': 'application/json' }
        });

        if (!response.ok) {
            throw new Error(`Server tr·∫£ v·ªÅ l·ªói: ${response.status}`);
        }

        const data = await response.json();
        console.log('[Ollama] API Response:', data);

        const models = data.models || [];
        console.log('[Ollama] Models found:', models.map(m => m.name));

        const modelBaseName = model.split(':')[0].toLowerCase();
        const modelExists = models.some(m => {
            const installedName = m.name.toLowerCase();
            return installedName === model.toLowerCase() ||
                installedName.startsWith(modelBaseName) ||
                installedName.includes(modelBaseName.split('/').pop());
        });

        console.log('[Ollama] Looking for:', model, 'Found:', modelExists);

        if (modelExists) {
            resultDiv.className = 'ollama-test-result success';
            resultDiv.textContent = `‚úÖ K·∫øt n·ªëi th√†nh c√¥ng!\n\nüì¶ Model "${model}" ƒë√£ s·∫µn s√†ng!\n\nüéâ B·∫°n c√≥ th·ªÉ b·∫Øt ƒë·∫ßu d·ªãch v·ªõi Ollama Local.\n\nüìã Models ƒë√£ c√†i: ${models.map(m => m.name).join(', ')}`;
        } else {
            resultDiv.className = 'ollama-test-result error';
            resultDiv.textContent = `‚ö†Ô∏è K·∫øt n·ªëi OK nh∆∞ng model "${model}" ch∆∞a ƒë∆∞·ª£c c√†i!\n\nüì• Ch·∫°y l·ªánh sau ƒë·ªÉ c√†i:\n   ollama pull ${model}\n\nüìã Models ƒë√£ c√†i: ${models.map(m => m.name).join(', ') || 'Kh√¥ng c√≥'}`;
        }

    } catch (error) {
        resultDiv.className = 'ollama-test-result error';

        if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
            resultDiv.textContent = `‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn Ollama!\n\nüîß Ki·ªÉm tra:\n1. Ollama ƒë√£ ch·∫°y ch∆∞a? (ollama serve)\n2. URL ƒë√∫ng ch∆∞a? (${url})\n3. Firewall c√≥ ch·∫∑n kh√¥ng?\n\nüì• T·∫£i Ollama: https://ollama.com/download`;
        } else {
            resultDiv.textContent = `‚ùå L·ªói: ${error.message}`;
        }
    }
}

// List installed Ollama models
async function listOllamaModels() {
    const resultDiv = document.getElementById('ollamaTestResult');
    const url = document.getElementById('ollamaUrl').value.trim();

    resultDiv.className = 'ollama-test-result info';
    resultDiv.textContent = 'üìã ƒêang l·∫•y danh s√°ch models...';

    try {
        const response = await fetch(`${url}/api/tags`, {
            method: 'GET',
            headers: { 'Content-Type': 'application/json' }
        });

        if (!response.ok) {
            throw new Error(`Server tr·∫£ v·ªÅ l·ªói: ${response.status}`);
        }

        const data = await response.json();
        const models = data.models || [];

        if (models.length === 0) {
            resultDiv.className = 'ollama-test-result error';
            resultDiv.textContent = '‚ö†Ô∏è Ch∆∞a c√≥ model n√†o ƒë∆∞·ª£c c√†i!\n\nüì• C√†i model khuy·∫øn ngh·ªã:\n   ollama pull huihui_ai/qwen3-abliterated:4b';
        } else {
            resultDiv.className = 'ollama-test-result success';
            let output = `üì¶ C√≥ ${models.length} model ƒë√£ c√†i:\n\n`;
            models.forEach((m, i) => {
                const sizeGB = (m.size / (1024 * 1024 * 1024)).toFixed(1);
                output += `${i + 1}. ${m.name} (${sizeGB}GB)\n`;
            });
            output += '\nüí° Click v√†o t√™n model ƒë·ªÉ s·ª≠ d·ª•ng.';
            resultDiv.textContent = output;
        }

    } catch (error) {
        resultDiv.className = 'ollama-test-result error';
        resultDiv.textContent = `‚ùå L·ªói: ${error.message}\n\nüîß ƒê·∫£m b·∫£o Ollama ƒëang ch·∫°y: ollama serve`;
    }
}

// ============================================
// TRANSLATION
// ============================================

// Tr√≠ch xu·∫•t k·∫øt qu·∫£ th·ª±c t·ª´ thinking output c·ªßa Qwen3
function extractResultFromThinking(thinkingText) {
    if (!thinkingText) return '';

    // B∆∞·ªõc 1: T√¨m marker k·∫øt qu·∫£ cu·ªëi c√πng
    const resultMarkers = [
        /Here(?:'s| is) the (?:rewritten|revised|translated|final)(?: version)?:?\s*/gi,
        /(?:Vi·∫øt l·∫°i|K·∫øt qu·∫£|B·∫£n d·ªãch|ƒêo·∫°n vƒÉn vi·∫øt l·∫°i):?\s*/gi,
        /(?:Final|Rewritten|Revised)(?: version)?:?\s*/gi,
        /---+\s*/g,
        /\n\n(?=")/,
    ];

    let result = thinkingText;

    for (const marker of resultMarkers) {
        const match = thinkingText.match(marker);
        if (match) {
            const idx = thinkingText.lastIndexOf(match[match.length - 1]);
            if (idx !== -1) {
                const afterMarker = thinkingText.substring(idx + match[match.length - 1].length).trim();
                if (afterMarker.length > 100) {
                    result = afterMarker;
                    console.log(`[Ollama] Extracted result after marker: "${match[match.length - 1].substring(0, 30)}..."`);
                    break;
                }
            }
        }
    }

    // B∆∞·ªõc 2: N·∫øu c√≥ l·∫´n thinking ti·∫øng Anh, l·ªçc l·∫•y TO√ÄN B·ªò c√°c kh·ªëi ti·∫øng Vi·ªát
    if (result.includes('Okay') || result.includes('Let me') || result.includes('I need to')) {
        const vietnameseBlocks = result.split(/\n\n+/).filter(block => {
            const hasVietnamese = /[√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë]/i.test(block);
            const startsWithEnglish = /^(Okay|Let me|I need|I'll|First|The|So|Now|Wait|Actually|Hmm)/i.test(block.trim());
            return hasVietnamese && !startsWithEnglish && block.length > 50;
        });

        if (vietnameseBlocks.length > 0) {
            // S·ª¨A L·ªñI: GH√âP T·∫§T C·∫¢ c√°c kh·ªëi Vietnamese thay v√¨ ch·ªâ l·∫•y m·ªôt
            result = vietnameseBlocks.join('\n\n');
            console.log(`[Ollama] Extracted ${vietnameseBlocks.length} Vietnamese blocks: ${result.length} chars total`);
        }
    }

    return result.trim();
}

// Translate with Ollama API
async function translateWithOllama(text, temperature = 0.7) {
    const url = document.getElementById('ollamaUrl').value.trim() || ollamaUrl;
    const model = document.getElementById('ollamaModel').value.trim() || ollamaModel;

    const startTime = Date.now();
    console.log(`[Ollama] Calling ${model} at ${url}...`);
    console.log(`[Ollama] Text length: ${text.length} chars`);

    let processedText = text;

    // Auto-detect model type v√† l·∫•y settings t·ªëi ∆∞u
    const modelType = detectModelType(model);
    let modelSettings = {
        temperature: temperature,
        top_p: 0.9,
        top_k: 40,
        num_predict: 4096,
        num_ctx: 8192
    };
    let useThinking = false;

    // Override v·ªõi preset n·∫øu c√≥
    if (modelType && typeof MODEL_PRESETS !== 'undefined' && MODEL_PRESETS[modelType]) {
        const preset = MODEL_PRESETS[modelType];
        modelSettings = { ...modelSettings, ...preset.settings };
        useThinking = preset.features.includes('think');
        console.log(`[Ollama] Auto-detected: ${preset.name}, thinking: ${useThinking}`);
    }

    const body = {
        model: model,
        messages: [
            { role: 'user', content: processedText }
        ],
        stream: false,
        options: modelSettings
    };

    // B·∫≠t thinking mode n·∫øu model h·ªó tr·ª£
    if (useThinking) {
        body.think = true;
    }

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 300000);

    let response;
    try {
        response = await fetch(`${url}/api/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(body),
            signal: controller.signal
        });
    } catch (fetchError) {
        clearTimeout(timeoutId);
        if (fetchError.name === 'AbortError') {
            throw new Error(`Ollama timeout sau 300s - Chunk qu√° d√†i ho·∫∑c model qu√° ch·∫≠m.`);
        }
        if (fetchError.message.includes('Failed to fetch')) {
            throw new Error('Kh√¥ng th·ªÉ k·∫øt n·ªëi Ollama. ƒê·∫£m b·∫£o Ollama ƒëang ch·∫°y!');
        }
        throw fetchError;
    }
    clearTimeout(timeoutId);

    if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        const errorMsg = errorData.error || `HTTP ${response.status}`;
        console.error(`[Ollama ERROR] Status: ${response.status}`);
        console.error(`[Ollama ERROR] Message: ${errorMsg}`);
        throw new Error(errorMsg);
    }

    const data = await response.json();
    const processingTime = (Date.now() - startTime) / 1000;
    console.log(`[Ollama] Response received in ${processingTime.toFixed(1)}s`);

    if (typeof updateOllamaSpeed === 'function') {
        updateOllamaSpeed(processingTime);
    }

    if (data.message) {
        let contentResult = '';
        let thinkingResult = '';

        // L·∫•y content n·∫øu c√≥
        if (data.message.content && data.message.content.trim()) {
            contentResult = data.message.content.trim();
            console.log(`[Ollama] message.content: ${contentResult.length} chars`);
        }

        // L·∫•y t·ª´ thinking n·∫øu c√≥
        if (data.message.thinking && data.message.thinking.trim()) {
            let thinkingText = data.message.thinking.trim();
            console.log(`[Ollama] message.thinking: ${thinkingText.length} chars`);
            thinkingResult = extractResultFromThinking(thinkingText);
            console.log(`[Ollama] Extracted from thinking: ${thinkingResult.length} chars`);
        }

        // SMART SELECT: Ch·ªçn k·∫øt qu·∫£ t·ªët h∆°n
        let result = '';
        const vietnamesePattern = /[√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë]/i;

        const contentHasVietnamese = vietnamesePattern.test(contentResult);
        const thinkingHasVietnamese = vietnamesePattern.test(thinkingResult);

        if (contentResult && thinkingResult) {
            // C·∫£ hai ƒë·ªÅu c√≥ ‚Üí ch·ªçn c√°i d√†i h∆°n c√≥ ti·∫øng Vi·ªát
            if (contentHasVietnamese && contentResult.length >= thinkingResult.length * 0.7) {
                result = contentResult;
                console.log(`[Ollama] ‚úÖ Selected: content (longer or similar, has Vietnamese)`);
            } else if (thinkingHasVietnamese && thinkingResult.length > contentResult.length) {
                result = thinkingResult;
                console.log(`[Ollama] ‚úÖ Selected: thinking (longer, has Vietnamese)`);
            } else {
                result = contentResult.length >= thinkingResult.length ? contentResult : thinkingResult;
                console.log(`[Ollama] ‚úÖ Selected: ${result === contentResult ? 'content' : 'thinking'} (fallback)`);
            }
        } else if (contentResult) {
            result = contentResult;
            console.log(`[Ollama] ‚úÖ Using content (only option)`);
        } else if (thinkingResult) {
            result = thinkingResult;
            console.log(`[Ollama] ‚úÖ Using thinking (only option)`);
        }

        if (result) {
            result = cleanGeminiResponse(result);
            console.log(`[Ollama] Final result: ${result.length} chars`);
            return result;
        }
    }

    if (data.response) {
        let result = data.response.trim();
        result = cleanGeminiResponse(result);
        return result;
    }

    console.error('[Ollama] Invalid response:', JSON.stringify(data));
    throw new Error('Ollama API: Invalid response format');
}

// ============================================
// SETTINGS
// ============================================

function saveOllamaSettings() {
    ollamaUrl = document.getElementById('ollamaUrl')?.value.trim() || ollamaUrl;
    ollamaModel = document.getElementById('ollamaModel')?.value.trim() || ollamaModel;

    const ollamaSettings = {
        useOllama: useOllama,
        ollamaUrl: ollamaUrl,
        ollamaModel: ollamaModel
    };

    localStorage.setItem('novelTranslatorOllamaSettings', JSON.stringify(ollamaSettings));
    console.log('[Ollama] Settings saved:', ollamaSettings);
}

function loadOllamaSettings() {
    const saved = localStorage.getItem('novelTranslatorOllamaSettings');
    if (saved) {
        try {
            const settings = JSON.parse(saved);
            useOllama = settings.useOllama || false;
            ollamaUrl = settings.ollamaUrl || 'http://localhost:11434';
            ollamaModel = settings.ollamaModel || 'huihui_ai/qwen3-abliterated:4b';

            const toggle = document.getElementById('useOllamaToggle');
            const settingsDiv = document.getElementById('ollamaSettings');
            const badge = document.getElementById('ollamaStatus');
            const urlInput = document.getElementById('ollamaUrl');
            const modelInput = document.getElementById('ollamaModel');

            if (toggle) toggle.checked = useOllama;
            if (urlInput) urlInput.value = ollamaUrl;
            if (modelInput) modelInput.value = ollamaModel;

            if (useOllama) {
                if (settingsDiv) settingsDiv.style.display = 'block';
                if (badge) {
                    badge.textContent = 'B·∫≠t';
                    badge.classList.add('active');
                }
            }

            console.log('[Ollama] Settings loaded:', settings);
        } catch (e) {
            console.error('[Ollama] Error loading settings:', e);
        }
    }
}

function setupOllamaEventListeners() {
    const urlInput = document.getElementById('ollamaUrl');
    const modelInput = document.getElementById('ollamaModel');

    if (urlInput) {
        urlInput.addEventListener('change', saveOllamaSettings);
    }
    if (modelInput) {
        modelInput.addEventListener('change', saveOllamaSettings);
    }
}

// ============================================
// MODEL DROPDOWN
// ============================================

async function loadOllamaModelsDropdown() {
    const select = document.getElementById('ollamaModelSelect');
    const url = document.getElementById('ollamaUrl').value.trim() || ollamaUrl;

    select.innerHTML = '<option value="">‚è≥ ƒêang t·∫£i...</option>';

    try {
        const response = await fetch(`${url}/api/tags`, {
            method: 'GET',
            headers: { 'Content-Type': 'application/json' }
        });

        if (!response.ok) {
            throw new Error(`HTTP ${response.status}`);
        }

        const data = await response.json();
        const models = data.models || [];

        if (models.length === 0) {
            select.innerHTML = '<option value="">‚ùå Ch∆∞a c√≥ model n√†o</option>';
            showToast('Ch∆∞a c√≥ model n√†o ƒë∆∞·ª£c c√†i. Ch·∫°y: ollama pull <model>', 'warning');
            return;
        }

        select.innerHTML = '<option value="">-- Ch·ªçn model --</option>';
        models.forEach(m => {
            const sizeGB = (m.size / (1024 * 1024 * 1024)).toFixed(1);
            const option = document.createElement('option');
            option.value = m.name;
            option.textContent = `${m.name} (${sizeGB}GB)`;
            select.appendChild(option);
        });

        const currentModel = document.getElementById('ollamaModel').value;
        if (currentModel) {
            select.value = currentModel;
        }

        showToast(`ƒê√£ t·∫£i ${models.length} models!`, 'success');

    } catch (error) {
        select.innerHTML = '<option value="">‚ùå L·ªói k·∫øt n·ªëi</option>';
        showToast(`L·ªói: ${error.message}`, 'error');
    }
}

function selectOllamaModel() {
    const select = document.getElementById('ollamaModelSelect');
    const input = document.getElementById('ollamaModel');

    if (select.value) {
        input.value = select.value;
        ollamaModel = select.value;
        saveOllamaSettings();
        showToast(`ƒê√£ ch·ªçn model: ${select.value}`, 'success');
    }
}

// ============================================
// SPEED TRACKING
// ============================================

function updateOllamaSpeed(chunkTime) {
    ollamaChunkTimes.push(chunkTime);
    ollamaTotalChunks++;

    if (ollamaChunkTimes.length > 10) {
        ollamaChunkTimes.shift();
    }

    const avgTime = ollamaChunkTimes.reduce((a, b) => a + b, 0) / ollamaChunkTimes.length;

    const speedDiv = document.getElementById('ollamaSpeedInfo');
    const speedValue = document.getElementById('ollamaSpeedValue');
    const chunksProcessed = document.getElementById('ollamaChunksProcessed');

    if (speedDiv && speedValue && chunksProcessed) {
        speedDiv.style.display = 'flex';
        speedValue.textContent = avgTime.toFixed(1);
        chunksProcessed.textContent = ollamaTotalChunks;
    }
}

function resetOllamaSpeed() {
    ollamaChunkTimes = [];
    ollamaTotalChunks = 0;
    const speedDiv = document.getElementById('ollamaSpeedInfo');
    if (speedDiv) {
        speedDiv.style.display = 'none';
    }
}

// ============================================
// TEST TRANSLATION
// ============================================

async function testOllamaTranslation() {
    const resultDiv = document.getElementById('ollamaTestResult');
    const url = document.getElementById('ollamaUrl').value.trim() || 'http://localhost:11434';
    const model = document.getElementById('ollamaModel').value.trim() || ollamaModel;

    resultDiv.className = 'ollama-test-result info';
    resultDiv.textContent = 'üß™ ƒêang test d·ªãch th·ª≠... ƒê·ª£i 10-30 gi√¢y...';

    let testText = 'Vi·∫øt l·∫°i cho m∆∞·ª£t m√†: Ta ng·ª≠a m·∫∑t Quan Thi√™n, h∆∞·ªõng v·ªÅ kia v·∫°n b√™n trong tr·ªùi quang ch·ª≠i ·∫ßm l√™n.';
    const systemPrompt = 'You are a translator. Output ONLY the translation, nothing else. No explanations.';

    console.log('[Test] Starting translation test...');
    console.log('[Test] URL:', url);
    console.log('[Test] Model:', model);
    console.log('[Test] Text:', testText);

    try {
        const startTime = Date.now();

        const response = await fetch(`${url}/api/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: model,
                messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: testText }
                ],
                stream: false,
                think: model.toLowerCase().includes('qwen3') ? true : undefined,
                options: { num_predict: 256 }
            })
        });

        console.log('[Test] Response status:', response.status);

        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(errorData.error || `HTTP ${response.status}`);
        }

        const data = await response.json();
        const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);

        console.log('[Test] Full response data:', JSON.stringify(data, null, 2));

        let content = null;

        if (data.message && typeof data.message === 'object' && data.message.content && data.message.content.trim()) {
            content = data.message.content;
            console.log('[Test] Using message.content format');
        }
        else if (data.message && data.message.thinking && data.message.thinking.trim()) {
            content = data.message.thinking;
            console.log('[Test] Using message.thinking format (Qwen3 mode)');
        }
        else if (data.response) {
            content = data.response;
            console.log('[Test] Using response format');
        }
        else if (typeof data === 'string') {
            content = data;
            console.log('[Test] Using string format');
        }
        else if (typeof data.message === 'string') {
            content = data.message;
            console.log('[Test] Using message string format');
        }

        if (content) {
            resultDiv.className = 'ollama-test-result success';
            resultDiv.textContent = `‚úÖ TH√ÄNH C√îNG! (${elapsed}s)\n\nüìù K·∫øt qu·∫£: ${content}\n\nüéâ Ollama ho·∫°t ƒë·ªông t·ªët!`;
            console.log('[Test] SUCCESS! Content:', content);
        } else {
            console.error('[Test] Unknown response format. Keys:', Object.keys(data));
            resultDiv.className = 'ollama-test-result error';
            resultDiv.textContent = `‚ùå Response format l·∫°. Xem Console ƒë·ªÉ debug.\n\nData keys: ${Object.keys(data).join(', ')}`;
        }

    } catch (error) {
        console.error('[Test] Error:', error);
        resultDiv.className = 'ollama-test-result error';
        resultDiv.textContent = `‚ùå L·ªñI: ${error.message}\n\nüîß Ki·ªÉm tra:\n1. Ollama ƒëang ch·∫°y?\n2. Model ƒë√£ c√†i?\n3. URL ƒë√∫ng?`;
    }
}

// ============================================
// START SERVER GUIDE
// ============================================

function showStartServerGuide() {
    const resultDiv = document.getElementById('ollamaTestResult');
    resultDiv.className = 'ollama-test-result info';
    resultDiv.innerHTML = `
<h4>üñ•Ô∏è H∆∞·ªõng d·∫´n ch·∫°y Ollama Server</h4>

<p><strong>B∆∞·ªõc 1:</strong> M·ªü Terminal/Command Prompt</p>

<p><strong>B∆∞·ªõc 2:</strong> Ch·∫°y l·ªánh sau:</p>
<div style="background: #1a1a2e; padding: 10px; border-radius: 8px; margin: 10px 0;">
    <code style="color: #10b981; font-size: 14px;">ollama serve</code>
    <button onclick="copyCommand('ollama serve')" style="margin-left: 10px; padding: 5px 10px; cursor: pointer;">üìã Copy</button>
</div>

<p><strong>B∆∞·ªõc 3:</strong> N·∫øu ch∆∞a c√≥ model, c√†i model:</p>
<div style="background: #1a1a2e; padding: 10px; border-radius: 8px; margin: 10px 0;">
    <code style="color: #10b981; font-size: 14px;">ollama pull qwen3:4b</code>
    <button onclick="copyCommand('ollama pull qwen3:4b')" style="margin-left: 10px; padding: 5px 10px; cursor: pointer;">üìã Copy</button>
</div>

<p><strong>Models khuy·∫øn ngh·ªã:</strong></p>
<ul style="margin: 10px 0; padding-left: 20px;">
    <li><code>qwen3:4b</code> - Nhanh, t·ªët cho d·ªãch truy·ªán ‚≠ê</li>
    <li><code>qwen3:8b</code> - Ch·∫•t l∆∞·ª£ng cao h∆°n</li>
    <li><code>llama3.2:3b</code> - Nh·∫π, nhanh</li>
    <li><code>gemma2:9b</code> - Ch·∫•t l∆∞·ª£ng t·ªët</li>
</ul>

<p style="color: #f59e0b;">‚ö†Ô∏è L∆∞u √Ω: Gi·ªØ terminal m·ªü khi d·ªãch!</p>
    `;
}

function copyCommand(cmd) {
    navigator.clipboard.writeText(cmd).then(() => {
        showToast('ƒê√£ copy: ' + cmd, 'success');
    });
}

// ============================================
// MODEL PRESETS - C√†i ƒë·∫∑t t·ªëi ∆∞u cho t·ª´ng model
// ============================================

const MODEL_PRESETS = {
    qwen3: {
        name: 'Qwen3',
        models: ['qwen3:4b', 'qwen3:8b', 'huihui_ai/qwen3-abliterated:4b'],
        recommended: 'qwen3:4b',
        settings: {
            temperature: 0.7,
            num_predict: 4096,
            num_ctx: 8192,
            top_p: 0.9,
            top_k: 40
        },
        features: ['think'],  // Qwen3 h·ªó tr·ª£ thinking mode
        tips: 'H·ªó tr·ª£ thinking mode, t·ªët cho d·ªãch vƒÉn h·ªçc'
    },
    llama3: {
        name: 'Llama3',
        models: ['llama3.2:3b', 'llama3.2:8b', 'llama3:8b'],
        recommended: 'llama3.2:3b',
        settings: {
            temperature: 0.7,
            num_predict: 4096,
            num_ctx: 8192,
            top_p: 0.9,
            top_k: 40
        },
        features: [],
        tips: 'ƒêa nƒÉng, nhanh, h·ªó tr·ª£ ti·∫øng Vi·ªát t·ªët'
    },
    gemma2: {
        name: 'Gemma2',
        models: ['gemma2:2b', 'gemma2:9b', 'gemma2:27b'],
        recommended: 'gemma2:9b',
        settings: {
            temperature: 0.7,
            num_predict: 4096,
            num_ctx: 8192,
            top_p: 0.95,
            top_k: 50
        },
        features: [],
        tips: 'C·ªßa Google, ch·∫•t l∆∞·ª£ng cao'
    },
    mistral: {
        name: 'Mistral',
        models: ['mistral:7b', 'mistral-nemo:12b'],
        recommended: 'mistral:7b',
        settings: {
            temperature: 0.7,
            num_predict: 4096,
            num_ctx: 8192,
            top_p: 0.9,
            top_k: 40
        },
        features: [],
        tips: 'Nh·∫π, nhanh, ch·∫•t l∆∞·ª£ng ·ªïn ƒë·ªãnh'
    },
    phi3: {
        name: 'Phi3',
        models: ['phi3:mini', 'phi3:medium'],
        recommended: 'phi3:mini',
        settings: {
            temperature: 0.7,
            num_predict: 4096,
            num_ctx: 4096,
            top_p: 0.9,
            top_k: 40
        },
        features: [],
        tips: 'C·ªßa Microsoft, r·∫•t nh·∫π'
    }
};

// √Åp d·ª•ng preset cho model
function applyModelPreset(presetKey) {
    const preset = MODEL_PRESETS[presetKey];
    if (!preset) {
        showToast('Kh√¥ng t√¨m th·∫•y preset!', 'error');
        return;
    }

    const modelInput = document.getElementById('ollamaModel');
    modelInput.value = preset.recommended;
    ollamaModel = preset.recommended;

    // L∆∞u settings cho model n√†y
    localStorage.setItem('ollamaModelPreset', JSON.stringify({
        presetKey: presetKey,
        model: preset.recommended,
        settings: preset.settings,
        features: preset.features
    }));

    saveOllamaSettings();

    const resultDiv = document.getElementById('ollamaTestResult');
    resultDiv.className = 'ollama-test-result success';
    resultDiv.innerHTML = `
‚úÖ <strong>ƒê√£ ch·ªçn ${preset.name}!</strong>

üì¶ Model: <code>${preset.recommended}</code>
‚öôÔ∏è Settings ƒë√£ t·ªëi ∆∞u t·ª± ƒë·ªông

üí° <strong>Tip:</strong> ${preset.tips}

üì• N·∫øu ch∆∞a c√≥ model, ch·∫°y l·ªánh:
<div style="background: #1a1a2e; padding: 8px; border-radius: 6px; margin-top: 5px;">
    <code style="color: #10b981;">ollama pull ${preset.recommended}</code>
    <button onclick="copyCommand('ollama pull ${preset.recommended}')" style="margin-left: 10px; padding: 3px 8px; cursor: pointer;">üìã</button>
</div>
    `;

    showToast(`ƒê√£ ch·ªçn ${preset.name}! Settings t·ªëi ∆∞u ƒë√£ √°p d·ª•ng.`, 'success');
}

// Auto-detect model type t·ª´ t√™n model
function detectModelType(modelName) {
    const name = modelName.toLowerCase();

    if (name.includes('qwen')) return 'qwen3';
    if (name.includes('llama')) return 'llama3';
    if (name.includes('gemma')) return 'gemma2';
    if (name.includes('mistral')) return 'mistral';
    if (name.includes('phi')) return 'phi3';

    return null;
}

// L·∫•y settings t·ªëi ∆∞u cho model hi·ªán t·∫°i
function getModelSettings() {
    const saved = localStorage.getItem('ollamaModelPreset');
    if (saved) {
        try {
            return JSON.parse(saved);
        } catch (e) { }
    }

    // Fallback: detect t·ª´ t√™n model
    const modelName = document.getElementById('ollamaModel')?.value || ollamaModel;
    const presetKey = detectModelType(modelName);

    if (presetKey && MODEL_PRESETS[presetKey]) {
        return {
            settings: MODEL_PRESETS[presetKey].settings,
            features: MODEL_PRESETS[presetKey].features
        };
    }

    // Default settings
    return {
        settings: {
            temperature: 0.7,
            num_predict: 4096,
            num_ctx: 8192,
            top_p: 0.9,
            top_k: 40
        },
        features: []
    };
}

// ============================================
// INITIALIZE
// ============================================

document.addEventListener('DOMContentLoaded', () => {
    setTimeout(() => {
        loadOllamaSettings();
        setupOllamaEventListeners();
    }, 100);
});

// Expose globally
window.toggleOllamaMode = toggleOllamaMode;
window.testOllamaConnection = testOllamaConnection;
window.listOllamaModels = listOllamaModels;
window.translateWithOllama = translateWithOllama;
window.loadOllamaModelsDropdown = loadOllamaModelsDropdown;
window.selectOllamaModel = selectOllamaModel;
window.updateOllamaSpeed = updateOllamaSpeed;
window.resetOllamaSpeed = resetOllamaSpeed;
window.testOllamaTranslation = testOllamaTranslation;
window.showStartServerGuide = showStartServerGuide;
window.applyModelPreset = applyModelPreset;
window.copyCommand = copyCommand;
window.getModelSettings = getModelSettings;
window.detectModelType = detectModelType;
